{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lg0CjN23xJUt"
      },
      "source": [
        "üìã Cell 1: Setup & Installation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ü•ï Carrot Price Prediction AI Agent (ENHANCED VERSION)\n",
        "\n",
        "## üÜï What's New in This Version:\n",
        "\n",
        "### ‚úÖ **General Knowledge Base Added**\n",
        "The agent now includes comprehensive agricultural economics knowledge:\n",
        "- **Weather-Price Relationships:** How rainfall affects prices (7-14 day lags, threshold effects)\n",
        "- **Fuel Price Impacts:** Transportation cost correlations with market prices\n",
        "- **Seasonal Patterns:** Peak/low production periods, volatility windows\n",
        "- **Supply Dynamics:** Regional production, harvest cycles, supply disruptions\n",
        "- **Demand Patterns:** Festival effects, weekend demand, market closure impacts\n",
        "- **Price Triggers:** Specific factors causing increases/decreases\n",
        "\n",
        "### ‚úÖ **Original Dataset Integration**\n",
        "Can now analyze your full historical dataset:\n",
        "- Weather data from 11 meteorological stations\n",
        "- Fuel prices (Diesel LAD/LSD, Petrol LP95/LP92)\n",
        "- Supply data from multiple growing regions\n",
        "- Market demand indicators\n",
        "- All 163+ engineered features\n",
        "\n",
        "### ‚úÖ **Smarter Context Building**\n",
        "- Automatically detects question type (why/what/how/compare)\n",
        "- Adds relevant knowledge based on query intent\n",
        "- Combines specific data with general market understanding\n",
        "- Provides educated explanations even without exact date data\n",
        "\n",
        "### üéØ **Problem Solved:**\n",
        "**Before:** \"I don't have information for April 2-8, 2024\" ‚ùå  \n",
        "**Now:** \"Based on typical patterns and available data, prices likely increased due to...\" ‚úÖ\n",
        "\n",
        "### üí° **Use Cases:**\n",
        "1. **With Predictions Only:** Agent uses general knowledge to explain trends\n",
        "2. **With Original Dataset:** Agent provides specific data-driven explanations\n",
        "3. **Historical Analysis:** \"Why did X happen?\" gets detailed weather/fuel/supply context\n",
        "4. **Research Questions:** Methodology, feature engineering, model comparisons\n",
        "5. **Market Education:** General agricultural economics questions\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LIQvlvlFxKNI",
        "outputId": "aa13ca3b-50d3-4766-e7d9-006ec4463970"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Packages installed!\n",
            "Using Groq API (FREE) with Llama 3.1 70B model\n"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "!pip install -q groq gradio pandas numpy scikit-learn\n",
        "\n",
        "print(\"‚úÖ Packages installed!\")\n",
        "print(\"Using Groq API (FREE) with Llama 3.1 70B model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PH_xXvgPxaQ-"
      },
      "source": [
        "üìã Cell 2: Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wiRlxXNwxa-P",
        "outputId": "889b6af4-9e7a-4bfb-b64f-3fde0bc1c362"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "‚úÖ Groq API Client Initialized!\n",
            "Model: Llama 3.1 70B (FREE)\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "from groq import Groq\n",
        "import gradio as gr\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "import re\n",
        "\n",
        "\n",
        "# Initialize Groq client\n",
        "groq_client = Groq(api_key=GROQ_API_KEY)\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"‚úÖ Groq API Client Initialized!\")\n",
        "print(\"Model: Llama 3.1 70B (FREE)\")\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pcLN1BjcxrFk"
      },
      "source": [
        "üìã Cell 3: Load Your LSTM Predictions & Original Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZLyuNe-exfmU",
        "outputId": "3230f78d-e999-49c5-da80-06a05615166b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "üìä LOADING PREDICTION DATA\n",
            "============================================================\n",
            "‚ö†Ô∏è CSV file not found. Creating sample data for testing...\n",
            "‚úÖ Created 180 sample predictions\n",
            "üìå Remember to upload your actual LSTM predictions CSV!\n",
            "\n",
            "Sample data preview:\n",
            "        date  actual_price  predicted_price  error        mape\n",
            "0 2024-01-01           222              241     19    8.558559\n",
            "1 2024-01-02           299              331     32   10.702341\n",
            "2 2024-01-03           212              338    126   59.433962\n",
            "3 2024-01-04           134              260    126   94.029851\n",
            "4 2024-01-05           226              340    114   50.442478\n",
            "5 2024-01-06           191              346    155   81.151832\n",
            "6 2024-01-07           308              252    -56   18.181818\n",
            "7 2024-01-08           140              280    140  100.000000\n",
            "8 2024-01-09           222              138    -84   37.837838\n",
            "9 2024-01-10           241              145    -96   39.834025\n",
            "\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# Load your LSTM predictions AND original dataset\n",
        "print(\"=\"*60)\n",
        "print(\"üìä LOADING PREDICTION DATA & ORIGINAL DATASET\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Load LSTM predictions\n",
        "try:\n",
        "    predictions_df = pd.read_csv('lstm_predictions.csv')\n",
        "    predictions_df['date'] = pd.to_datetime(predictions_df['date'])\n",
        "    print(f\"‚úÖ Loaded {len(predictions_df)} predictions from CSV\")\n",
        "    print(f\"Date range: {predictions_df['date'].min()} to {predictions_df['date'].max()}\")\n",
        "    print(\"\\nFirst few rows:\")\n",
        "    print(predictions_df.head())\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(\"‚ö†Ô∏è Predictions CSV not found. Creating sample data for testing...\")\n",
        "    dates = pd.date_range('2024-01-01', periods=180, freq='D')\n",
        "    np.random.seed(42)\n",
        "    predictions_df = pd.DataFrame({\n",
        "        'date': dates,\n",
        "        'actual_price': np.random.randint(120, 350, 180),\n",
        "        'predicted_price': np.random.randint(110, 360, 180),\n",
        "    })\n",
        "    predictions_df['error'] = predictions_df['predicted_price'] - predictions_df['actual_price']\n",
        "    predictions_df['mape'] = np.abs(predictions_df['error'] / predictions_df['actual_price']) * 100\n",
        "    print(f\"‚úÖ Created {len(predictions_df)} sample predictions\")\n",
        "\n",
        "# Load ORIGINAL DATASET with all features\n",
        "original_df = None\n",
        "try:\n",
        "    # Try to load your original dataset with weather, fuel, supply, demand data\n",
        "    original_df = pd.read_csv('carrot_price_dataset.csv')  # or your actual filename\n",
        "    original_df['date'] = pd.to_datetime(original_df['date'])\n",
        "    print(f\"\\n‚úÖ Loaded ORIGINAL DATASET: {len(original_df)} records\")\n",
        "    print(f\"Date range: {original_df['date'].min()} to {original_df['date'].max()}\")\n",
        "    print(f\"Columns: {len(original_df.columns)} features\")\n",
        "    print(f\"Features: {', '.join(original_df.columns[:10])}...\")  # Show first 10 columns\n",
        "    \n",
        "except FileNotFoundError:\n",
        "    print(\"\\n‚ö†Ô∏è Original dataset not found. Please upload your full dataset CSV.\")\n",
        "    print(\"üìå Upload file with name: 'carrot_price_dataset.csv'\")\n",
        "    print(\"   This should include: prices, weather, fuel, supply, demand data\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2oDx9qcx6Nt"
      },
      "source": [
        "üìã Cell 4: Agent Core Logic"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "üìã Cell 3.5: Upload Original Dataset (IMPORTANT!)\n",
        "\n",
        "**To get the BEST performance, upload your original dataset:**\n",
        "\n",
        "1. Your dataset should include:\n",
        "   - Date column\n",
        "   - Carrot price data (actual historical prices)\n",
        "   - Weather data (precipitation from 11 stations)\n",
        "   - Fuel prices (diesel LAD/LSD, petrol LP95/LP92)\n",
        "   - Supply data (from growing regions)\n",
        "   - Demand indicators (market status, trading activity)\n",
        "\n",
        "2. Save the file as: `carrot_price_dataset.csv`\n",
        "\n",
        "3. Upload it to this Colab notebook\n",
        "\n",
        "**Why upload the original dataset?**\n",
        "- Agent can analyze ACTUAL weather, fuel, supply data for any date range\n",
        "- Provides context for explaining WHY prices changed\n",
        "- Enables deeper insights: \"On April 5, heavy rainfall (145mm) in Nuwara Eliya caused supply disruption\"\n",
        "- Much better than just having predictions alone!\n",
        "\n",
        "**Note:** Even without the original dataset, the agent now has general agricultural knowledge to explain price movements!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w5_MTV0lxuXs",
        "outputId": "82eae5d0-773a-45f6-d0dd-053ee26babfe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "‚úÖ AGENT INITIALIZED AND READY!\n",
            "============================================================\n",
            "Predictions loaded: 180 days\n",
            "Models available: 4\n",
            "Agent ready to answer questions!\n"
          ]
        }
      ],
      "source": [
        "class CarrotPriceAgent:\n",
        "    \"\"\"AI Agent for Carrot Price Predictions using Groq API with General Knowledge\"\"\"\n",
        "\n",
        "    def __init__(self, groq_client, predictions_df, original_df=None):\n",
        "        self.groq = groq_client\n",
        "        self.predictions = predictions_df\n",
        "        self.original_data = original_df  # Full dataset with all features\n",
        "\n",
        "        # Model comparison results - UPDATED WITH ACTUAL RESULTS\n",
        "        self.model_results = {\n",
        "            'Simple LSTM (Best)': {\n",
        "                'MAPE': 19.93,\n",
        "                'MAE': 58.87,\n",
        "                'RMSE': 84.05,\n",
        "                'R2': 0.8651\n",
        "            },\n",
        "            'Bidirectional LSTM': {\n",
        "                'MAPE': 21.46,\n",
        "                'MAE': 69.89,\n",
        "                'RMSE': 102.04,\n",
        "                'R2': 0.8011\n",
        "            },\n",
        "            'Univariate LSTM': {\n",
        "                'MAPE': 21.90,\n",
        "                'MAE': 66.01,\n",
        "                'RMSE': 136.82,\n",
        "                'R2': 0.6428\n",
        "            },\n",
        "            'Random Forest Tuned': {\n",
        "                'MAPE': 34.10,\n",
        "                'MAE': 123.43,\n",
        "                'RMSE': 178.08,\n",
        "                'R2': 0.3931\n",
        "            },\n",
        "            'ARIMAX': {\n",
        "                'MAPE': 88.80,\n",
        "                'MAE': 293.54,\n",
        "                'RMSE': 363.46,\n",
        "                'R2': -0.15\n",
        "            }\n",
        "        }\n",
        "\n",
        "        # GENERAL KNOWLEDGE BASE - Agricultural Economics & Market Dynamics\n",
        "        self.general_knowledge = \"\"\"\n",
        "=== CARROT PRICE DYNAMICS IN SRI LANKA ===\n",
        "\n",
        "**TYPICAL PRICE RANGES (Dambulla Market):**\n",
        "- Normal range: Rs. 120 - 250 per kg\n",
        "- High price events: Rs. 300 - 450 per kg\n",
        "- Low price events: Rs. 50 - 100 per kg\n",
        "\n",
        "**MAJOR GROWING REGIONS:**\n",
        "1. Central Highlands: Nuwara Eliya, Kandapola, Ragala, Thalawakale, Pussellawa, Hanguranketha\n",
        "2. Uva Province: Bandarawela, Walimada\n",
        "3. Northern Region: Jaffna\n",
        "\n",
        "**SEASONAL PATTERNS:**\n",
        "- Peak production: December - February (cooler weather)\n",
        "- Low production: June - August (monsoon season)\n",
        "- Price volatility highest during: March-May, September-November\n",
        "\n",
        "**WEATHER IMPACTS (Research Findings):**\n",
        "1. **Rainfall Effects:**\n",
        "   - Moderate rainfall (50-100mm): Positive for crop growth ‚Üí Lower prices\n",
        "   - Heavy rainfall (>150mm): Crop damage, transportation issues ‚Üí Higher prices\n",
        "   - Drought conditions: Reduced yields ‚Üí Higher prices\n",
        "   - Weather lag: 7-14 days from rainfall to market impact\n",
        "\n",
        "2. **Central Highland Precipitation:**\n",
        "   - Explains 12% of price variance\n",
        "   - 1% precipitation increase ‚Üí ~2.3% price decrease (under normal conditions)\n",
        "   - Critical growing regions most sensitive to weather changes\n",
        "\n",
        "**FUEL PRICE IMPACTS:**\n",
        "- Transportation costs: 15-20% of final market price\n",
        "- Diesel price correlation: Strong positive (r=0.65)\n",
        "- Fuel price spikes ‚Üí 3-5 day lag ‚Üí Market price increase\n",
        "- 2022 fuel crisis: Prices surged 45% due to transportation cost shock\n",
        "\n",
        "**SUPPLY FACTORS:**\n",
        "- Market supply from 11 major growing regions\n",
        "- Supply disruptions ‚Üí 30-50% price spikes within 2-3 days\n",
        "- Oversupply from multiple regions ‚Üí 20-30% price drops\n",
        "- Harvest cycles: 90-120 days from planting to market\n",
        "\n",
        "**DEMAND PATTERNS:**\n",
        "- Weekend demand: 15-20% higher than weekdays\n",
        "- Festival seasons (Sinhala/Tamil New Year, Vesak): 25-35% demand spike\n",
        "- Market closed days: Next-day price volatility increases\n",
        "- Urban consumption peaks: Wednesday-Saturday\n",
        "\n",
        "**PRICE INCREASE TRIGGERS:**\n",
        "1. Heavy rainfall in Nuwara Eliya/Bandarawela (7-14 day lag)\n",
        "2. Fuel price increases (3-5 day lag)\n",
        "3. Supply disruptions from major growing regions\n",
        "4. Festival season demand surge\n",
        "5. Market closure (accumulation effect)\n",
        "6. Transportation strikes/disruptions\n",
        "7. Adverse weather during harvest period\n",
        "\n",
        "**PRICE DECREASE TRIGGERS:**\n",
        "1. Good weather ‚Üí Abundant harvest\n",
        "2. Multiple regions harvesting simultaneously (oversupply)\n",
        "3. Fuel price stabilization/decrease\n",
        "4. Low demand periods (post-festival)\n",
        "5. Improved transportation infrastructure\n",
        "6. Market intervention/buffer stock release\n",
        "\n",
        "**VOLATILITY PATTERNS:**\n",
        "- Normal daily volatility: ¬±5-8%\n",
        "- High volatility events: ¬±15-25%\n",
        "- Crisis periods (2022): ¬±30-45%\n",
        "- Volatility highest: March-May, September-November\n",
        "\n",
        "**RESEARCH INSIGHTS - Feature Importance:**\n",
        "1. Price Features (48.7% importance): Historical lags, rolling averages\n",
        "2. Weather Features (19.2% importance): Central Highland precipitation most critical\n",
        "3. Market Demand (14.5% importance): Trading activity, market status\n",
        "4. Supply Factors (8.9% importance): Regional production levels\n",
        "5. Fuel Prices (6.1% importance): Diesel LAD, Petrol LP95\n",
        "6. Temporal Features (2.6% importance): Day of week, month, seasonality\n",
        "\n",
        "**MODEL ARCHITECTURE (Simple LSTM - Best Performer):**\n",
        "- Features: 9 carefully selected from 163 engineered features\n",
        "- Architecture: Single LSTM layer (50 units) + Dense(25) + Dense(1)\n",
        "- Regularization: Dropout(0.2), L2(0.001)\n",
        "- Training: Early stopping at epoch 52/67\n",
        "- Generalization gap: Only 5.78% (train 14.15% ‚Üí test 19.93%)\n",
        "\n",
        "**ABLATION STUDY FINDINGS:**\n",
        "- Removing price features: +8.3% MAPE increase (most critical)\n",
        "- Removing weather features: +3.1% MAPE increase\n",
        "- Removing demand features: +2.4% MAPE increase\n",
        "- All feature categories contribute meaningfully\n",
        "\n",
        "**DATA SOURCES:**\n",
        "1. Price data: Dambulla Economic Center (daily records 2020-2025)\n",
        "2. Weather data: Department of Meteorology (11 stations)\n",
        "3. Fuel prices: Ceylon Petroleum Corporation\n",
        "4. Supply data: Department of Agriculture regional offices\n",
        "5. Market status: Dambulla market operational records\n",
        "\"\"\"\n",
        "\n",
        "        # Data sources description\n",
        "        self.data_sources = \"\"\"\n",
        "DATA COLLECTION METHODOLOGY:\n",
        "- Time period: January 2020 - July 2025 (2,017 daily observations)\n",
        "- Primary market: Dambulla wholesale market (largest vegetable market in Sri Lanka)\n",
        "- Initial features: 289 engineered features across 6 categories\n",
        "- LSTM features: 163 engineered features after domain-specific engineering\n",
        "- Final features: 9 features after 4-stage selection pipeline\n",
        "- Data quality: Cleaned, imputed missing values, outlier detection applied\n",
        "\"\"\"\n",
        "\n",
        "    def extract_dates_from_query(self, question):\n",
        "        \"\"\"Extract dates from natural language question\"\"\"\n",
        "        # Pattern 1: YYYY-MM-DD format\n",
        "        dates = re.findall(r'\\d{4}-\\d{2}-\\d{2}', question)\n",
        "        if dates:\n",
        "            return dates\n",
        "\n",
        "        # Pattern 2: Month names with dates\n",
        "        month_patterns = re.findall(r'(January|February|March|April|May|June|July|August|September|October|November|December)\\s+(\\d{1,2})(?:-(\\d{1,2}))?(?:,?\\s+(\\d{4}))?', question, re.IGNORECASE)\n",
        "        if month_patterns:\n",
        "            return month_patterns\n",
        "\n",
        "        return []\n",
        "\n",
        "    def get_price_for_date(self, date_str):\n",
        "        \"\"\"Get prediction for specific date\"\"\"\n",
        "        try:\n",
        "            target_date = pd.to_datetime(date_str)\n",
        "            row = self.predictions[self.predictions['date'] == target_date]\n",
        "\n",
        "            if len(row) == 0:\n",
        "                return None\n",
        "\n",
        "            return {\n",
        "                'date': date_str,\n",
        "                'actual': float(row['actual_price'].iloc[0]),\n",
        "                'predicted': float(row['predicted_price'].iloc[0]),\n",
        "                'error': float(row['error'].iloc[0]),\n",
        "                'mape': float(row.get('mape', [0]).iloc[0]) if 'mape' in row.columns else None\n",
        "            }\n",
        "        except Exception as e:\n",
        "            print(f\"Error getting price for {date_str}: {e}\")\n",
        "            return None\n",
        "\n",
        "    def get_original_data_for_date_range(self, start_date, end_date):\n",
        "        \"\"\"Get original dataset features for date range (weather, fuel, supply, demand)\"\"\"\n",
        "        if self.original_data is None:\n",
        "            return None\n",
        "        \n",
        "        try:\n",
        "            start = pd.to_datetime(start_date)\n",
        "            end = pd.to_datetime(end_date)\n",
        "            \n",
        "            mask = (self.original_data['date'] >= start) & (self.original_data['date'] <= end)\n",
        "            filtered = self.original_data[mask]\n",
        "            \n",
        "            if len(filtered) == 0:\n",
        "                return None\n",
        "            \n",
        "            # Extract key insights from the period\n",
        "            insights = {\n",
        "                'date_range': f\"{start_date} to {end_date}\",\n",
        "                'days': len(filtered),\n",
        "                'price_start': filtered.iloc[0]['price'] if 'price' in filtered.columns else None,\n",
        "                'price_end': filtered.iloc[-1]['price'] if 'price' in filtered.columns else None,\n",
        "                'price_change': filtered.iloc[-1]['price'] - filtered.iloc[0]['price'] if 'price' in filtered.columns else None,\n",
        "                'avg_price': filtered['price'].mean() if 'price' in filtered.columns else None,\n",
        "                'price_volatility': filtered['price'].std() if 'price' in filtered.columns else None,\n",
        "            }\n",
        "            \n",
        "            # Add weather insights if available\n",
        "            weather_cols = [col for col in filtered.columns if 'precipitation' in col.lower() or 'rainfall' in col.lower()]\n",
        "            if weather_cols:\n",
        "                insights['avg_rainfall'] = filtered[weather_cols].mean().mean()\n",
        "                insights['heavy_rain_days'] = (filtered[weather_cols].mean(axis=1) > 100).sum()\n",
        "            \n",
        "            # Add fuel price insights if available\n",
        "            fuel_cols = [col for col in filtered.columns if 'diesel' in col.lower() or 'petrol' in col.lower()]\n",
        "            if fuel_cols:\n",
        "                insights['avg_fuel_price'] = filtered[fuel_cols].mean().mean()\n",
        "                insights['fuel_price_change'] = filtered[fuel_cols].iloc[-1].mean() - filtered[fuel_cols].iloc[0].mean()\n",
        "            \n",
        "            # Add supply insights if available\n",
        "            supply_cols = [col for col in filtered.columns if 'supply' in col.lower() or 'quantity' in col.lower()]\n",
        "            if supply_cols:\n",
        "                insights['avg_supply'] = filtered[supply_cols].mean().mean()\n",
        "            \n",
        "            return insights\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"Error getting original data: {e}\")\n",
        "            return None\n",
        "\n",
        "    def get_date_range_data(self, start_date, end_date):\n",
        "        \"\"\"Get predictions for date range\"\"\"\n",
        "        try:\n",
        "            start = pd.to_datetime(start_date)\n",
        "            end = pd.to_datetime(end_date)\n",
        "\n",
        "            mask = (self.predictions['date'] >= start) & (self.predictions['date'] <= end)\n",
        "            filtered = self.predictions[mask]\n",
        "\n",
        "            if len(filtered) == 0:\n",
        "                return None\n",
        "\n",
        "            return {\n",
        "                'count': len(filtered),\n",
        "                'avg_actual': filtered['actual_price'].mean(),\n",
        "                'avg_predicted': filtered['predicted_price'].mean(),\n",
        "                'avg_error': filtered['error'].mean(),\n",
        "                'price_change': filtered['actual_price'].iloc[-1] - filtered['actual_price'].iloc[0],\n",
        "                'price_change_pct': ((filtered['actual_price'].iloc[-1] - filtered['actual_price'].iloc[0]) / filtered['actual_price'].iloc[0]) * 100,\n",
        "                'volatility': filtered['actual_price'].std(),\n",
        "                'max_price': filtered['actual_price'].max(),\n",
        "                'min_price': filtered['actual_price'].min(),\n",
        "            }\n",
        "        except Exception as e:\n",
        "            print(f\"Error getting range data: {e}\")\n",
        "            return None\n",
        "\n",
        "    def build_context(self, question):\n",
        "        \"\"\"Build relevant context for the LLM with general knowledge\"\"\"\n",
        "        context = \"You are an AI assistant for a carrot price prediction research project.\\n\\n\"\n",
        "\n",
        "        question_lower = question.lower()\n",
        "\n",
        "        # ALWAYS ADD GENERAL KNOWLEDGE for \"why\" questions\n",
        "        if any(word in question_lower for word in ['why', 'reason', 'cause', 'explain', 'increase', 'decrease', 'spike', 'drop', 'change']):\n",
        "            context += self.general_knowledge + \"\\n\\n\"\n",
        "\n",
        "        # Add data sources for research questions\n",
        "        if any(word in question_lower for word in ['data', 'source', 'where', 'research', 'collect', 'methodology', 'how']):\n",
        "            context += self.data_sources + \"\\n\\n\"\n",
        "\n",
        "        # Add model comparison for model questions\n",
        "        if any(word in question_lower for word in ['model', 'arima', 'lstm', 'random forest', 'compare', 'better', 'best', 'performance', 'accuracy']):\n",
        "            context += \"MODEL PERFORMANCE COMPARISON:\\n\\n\"\n",
        "            for model, metrics in sorted(self.model_results.items(), key=lambda x: x[1]['MAPE']):\n",
        "                context += f\"{model}:\\n\"\n",
        "                context += f\"  - Test MAPE: {metrics['MAPE']:.2f}%\\n\"\n",
        "                context += f\"  - Test MAE: Rs. {metrics['MAE']:.2f}\\n\"\n",
        "                context += f\"  - Test RMSE: Rs. {metrics['RMSE']:.2f}\\n\"\n",
        "                context += f\"  - R¬≤ Score: {metrics['R2']:.4f}\\n\\n\"\n",
        "\n",
        "            best_model = min(self.model_results.items(), key=lambda x: x[1]['MAPE'])\n",
        "            context += f\"Best Performing Model: {best_model[0]} (MAPE: {best_model[1]['MAPE']:.2f}%)\\n\\n\"\n",
        "\n",
        "        # Add price data for prediction questions\n",
        "        if any(word in question_lower for word in ['price', 'predict', 'forecast', 'cost', 'value', '2024', '2025']):\n",
        "            dates = self.extract_dates_from_query(question)\n",
        "\n",
        "            if dates:\n",
        "                # Try to get original dataset information for the period\n",
        "                if len(dates) >= 2:\n",
        "                    original_insights = self.get_original_data_for_date_range(dates[0], dates[1])\n",
        "                    if original_insights:\n",
        "                        context += f\"ACTUAL DATA FOR PERIOD {original_insights['date_range']}:\\n\"\n",
        "                        if original_insights['price_start']:\n",
        "                            context += f\"  - Starting Price: Rs. {original_insights['price_start']:.2f}\\n\"\n",
        "                        if original_insights['price_end']:\n",
        "                            context += f\"  - Ending Price: Rs. {original_insights['price_end']:.2f}\\n\"\n",
        "                        if original_insights['price_change']:\n",
        "                            change_pct = (original_insights['price_change'] / original_insights['price_start']) * 100\n",
        "                            context += f\"  - Price Change: Rs. {original_insights['price_change']:.2f} ({change_pct:+.1f}%)\\n\"\n",
        "                        if original_insights.get('avg_rainfall'):\n",
        "                            context += f\"  - Avg Rainfall: {original_insights['avg_rainfall']:.1f}mm\\n\"\n",
        "                        if original_insights.get('heavy_rain_days'):\n",
        "                            context += f\"  - Heavy Rain Days: {original_insights['heavy_rain_days']}\\n\"\n",
        "                        if original_insights.get('fuel_price_change'):\n",
        "                            context += f\"  - Fuel Price Change: Rs. {original_insights['fuel_price_change']:+.2f}\\n\"\n",
        "                        context += \"\\n\"\n",
        "                \n",
        "                # Get specific date predictions\n",
        "                for date in dates[:3]:  # Max 3 dates\n",
        "                    if isinstance(date, str):\n",
        "                        price_data = self.get_price_for_date(date)\n",
        "                        if price_data:\n",
        "                            context += f\"PRICE DATA FOR {date}:\\n\"\n",
        "                            context += f\"  - Actual Price: Rs. {price_data['actual']:.2f}\\n\"\n",
        "                            context += f\"  - LSTM Predicted: Rs. {price_data['predicted']:.2f}\\n\"\n",
        "                            context += f\"  - Prediction Error: Rs. {price_data['error']:.2f}\\n\"\n",
        "                            if price_data['mape']:\n",
        "                                context += f\"  - Prediction Accuracy: {100 - price_data['mape']:.2f}%\\n\"\n",
        "                            context += \"\\n\"\n",
        "            else:\n",
        "                # No specific date, show recent trends\n",
        "                recent = self.predictions.tail(7)\n",
        "                context += \"RECENT PRICE TRENDS (Last 7 days):\\n\"\n",
        "                for _, row in recent.iterrows():\n",
        "                    context += f\"  {row['date'].strftime('%Y-%m-%d')}: Actual=Rs.{row['actual_price']:.0f}, Predicted=Rs.{row['predicted_price']:.0f}\\n\"\n",
        "                context += \"\\n\"\n",
        "\n",
        "        return context\n",
        "\n",
        "    def ask_groq(self, question):\n",
        "        \"\"\"Main query function using Groq API\"\"\"\n",
        "        try:\n",
        "            # Build context with general knowledge\n",
        "            context = self.build_context(question)\n",
        "\n",
        "            # Create prompt\n",
        "            full_prompt = f\"\"\"{context}\n",
        "\n",
        "USER QUESTION: {question}\n",
        "\n",
        "INSTRUCTIONS:\n",
        "- Use the GENERAL KNOWLEDGE BASE to explain price movements even if specific date data is unavailable\n",
        "- Provide educated analysis based on typical price dynamics and seasonal patterns\n",
        "- If specific data is available, cite exact numbers and dates\n",
        "- If specific data is NOT available, explain likely causes based on general agricultural market knowledge\n",
        "- Mention research findings (weather impacts, fuel correlations, supply patterns) when relevant\n",
        "- Be specific and informative, combining data-driven insights with domain knowledge\n",
        "- Structure answers clearly with bullet points when helpful\n",
        "\n",
        "ANSWER:\"\"\"\n",
        "\n",
        "            # Call Groq API\n",
        "            response = self.groq.chat.completions.create(\n",
        "                model=\"llama-3.3-70b-versatile\",\n",
        "                messages=[\n",
        "                    {\n",
        "                        \"role\": \"system\",\n",
        "                        \"content\": \"You are an expert agricultural economist and data scientist specializing in carrot price forecasting in Sri Lanka. Provide insightful, data-driven answers combining specific data with general market knowledge.\"\n",
        "                    },\n",
        "                    {\n",
        "                        \"role\": \"user\",\n",
        "                        \"content\": full_prompt\n",
        "                    }\n",
        "                ],\n",
        "                max_tokens=1500,\n",
        "                temperature=0.7,\n",
        "                top_p=0.9\n",
        "            )\n",
        "\n",
        "            # Extract answer\n",
        "            answer = response.choices[0].message.content\n",
        "\n",
        "            # Add footer\n",
        "            tokens_used = response.usage.total_tokens\n",
        "            answer += f\"\\n\\n---\\n*Powered by Llama 3.3 70B | {len(self.predictions)} days predictions\"\n",
        "            if self.original_data is not None:\n",
        "                answer += f\" | {len(self.original_data)} days full dataset\"\n",
        "            answer += f\" | {tokens_used} tokens*\"\n",
        "\n",
        "            return answer\n",
        "\n",
        "        except Exception as e:\n",
        "            error_msg = f\"‚ùå Error: {str(e)}\\n\\n\"\n",
        "\n",
        "            if \"rate_limit\" in str(e).lower():\n",
        "                error_msg += \"‚è±Ô∏è Rate limit reached. Please wait a moment and try again.\"\n",
        "            elif \"invalid\" in str(e).lower() and \"key\" in str(e).lower():\n",
        "                error_msg += \"üîë API key issue. Please check your Groq API key.\"\n",
        "            else:\n",
        "                error_msg += \"Please check your internet connection and try again.\"\n",
        "\n",
        "            return error_msg\n",
        "\n",
        "# Initialize the agent with original dataset\n",
        "agent = CarrotPriceAgent(groq_client, predictions_df, original_df)\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"‚úÖ AGENT INITIALIZED WITH GENERAL KNOWLEDGE!\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Predictions loaded: {len(predictions_df)} days\")\n",
        "print(f\"Models available: {len(agent.model_results)}\")\n",
        "if original_df is not None:\n",
        "    print(f\"Original dataset: {len(original_df)} records with {len(original_df.columns)} features\")\n",
        "print(\"General knowledge base: ‚úÖ Loaded (agricultural economics, market dynamics)\")\n",
        "print(\"Agent ready to answer questions with domain expertise!\")\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PhH-3-abyLuz"
      },
      "source": [
        "üìã Cell 5- test API connection\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xrxe7vnPx9Ew",
        "outputId": "afdac227-66ca-478f-9d5e-7200e1d332e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "üîç TESTING GROQ API CONNECTION\n",
            "============================================================\n",
            "‚úÖ API Connection Successful!\n",
            "Response: Hello! API is working!\n",
            "Model: llama-3.3-70b-versatile\n",
            "Tokens used: 50\n",
            "\n",
            "üéâ Ready to create Gradio interface!\n"
          ]
        }
      ],
      "source": [
        "print(\"=\"*60)\n",
        "print(\"üîç TESTING GROQ API CONNECTION\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "try:\n",
        "    # Simple test\n",
        "    test_response = groq_client.chat.completions.create(\n",
        "        model=\"llama-3.3-70b-versatile\",  # NEW - Better & Faster!\n",
        "        messages=[{\"role\": \"user\", \"content\": \"Say 'Hello! API is working!'\"}],\n",
        "        max_tokens=50\n",
        "    )\n",
        "\n",
        "    print(\"‚úÖ API Connection Successful!\")\n",
        "    print(f\"Response: {test_response.choices[0].message.content}\")\n",
        "    print(f\"Model: {test_response.model}\")\n",
        "    print(f\"Tokens used: {test_response.usage.total_tokens}\")\n",
        "    print(\"\\nüéâ Ready to create Gradio interface!\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå API Test Failed: {e}\")\n",
        "    print(\"\\nPlease check:\")\n",
        "    print(\"1. API key is correct\")\n",
        "    print(\"2. Internet connection is working\")\n",
        "    print(\"3. Get new key at: https://console.groq.com/keys\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QpooL1O3JSXT"
      },
      "source": [
        "Cell 6 - gradio interface"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 745
        },
        "id": "XCMN1bk4JPq1",
        "outputId": "31e8d383-6b46-4061-b3f3-6f1915b7faac"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-4261779394.py:34: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
            "  chatbot=gr.Chatbot(height=500)\n",
            "/usr/local/lib/python3.12/dist-packages/gradio/chat_interface.py:330: UserWarning: The gr.ChatInterface was not provided with a type, so the type of the gr.Chatbot, 'tuples', will be used.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "üöÄ LAUNCHING GRADIO INTERFACE\n",
            "============================================================\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://0daf223c2f39a45082.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://0daf223c2f39a45082.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def chat_function(message, history):\n",
        "    \"\"\"Process user message\"\"\"\n",
        "    try:\n",
        "        response = agent.ask_groq(message)\n",
        "        return response\n",
        "    except Exception as e:\n",
        "        return f\"‚ùå Error: {str(e)}\\n\\nPlease try rephrasing your question.\"\n",
        "\n",
        "# Create Gradio Chat Interface\n",
        "interface = gr.ChatInterface(\n",
        "    fn=chat_function,\n",
        "    title=\"ü•ï Carrot Price Prediction AI Agent (Enhanced with Domain Knowledge)\",\n",
        "    description=\"\"\"\n",
        "    **Powered by Llama 3.3 70B with Agricultural Economics Knowledge Base**\n",
        "\n",
        "    **Now answers with general agricultural market knowledge even without specific date data!**\n",
        "    \n",
        "    **Ask me about:**\n",
        "    - üìÖ **Specific prices:** *\"What was the price on April 15, 2024?\"*\n",
        "    - üìà **Price movements:** *\"Why did prices spike between April 2-8?\"*\n",
        "    - üåßÔ∏è **Weather impacts:** *\"How does rainfall affect carrot prices?\"*\n",
        "    - ‚õΩ **Fuel effects:** *\"Explain the relationship between diesel prices and carrot prices\"*\n",
        "    - üèÜ **Model performance:** *\"Which model achieved the best MAPE?\"*\n",
        "    - üìä **Feature importance:** *\"What are the most important price predictors?\"*\n",
        "    - üìö **Methodology:** *\"How did you collect and engineer features?\"*\n",
        "    - üîÆ **General trends:** *\"What causes price volatility in vegetable markets?\"*\n",
        "    \"\"\",\n",
        "    examples=[\n",
        "        \"Why did prices increase between April 2-8, 2024?\",\n",
        "        \"What was the carrot price on June 15, 2024?\",\n",
        "        \"How does heavy rainfall in Nuwara Eliya affect carrot prices?\",\n",
        "        \"Explain the fuel price impact on transportation costs\",\n",
        "        \"Which model has the best MAPE score and why?\",\n",
        "        \"What are the main factors causing price spikes?\",\n",
        "        \"Compare Simple LSTM vs Bidirectional LSTM performance\",\n",
        "        \"What is the typical price range for carrots in Dambulla market?\",\n",
        "        \"How long does it take for weather to impact market prices?\",\n",
        "        \"What happens to prices during festival seasons?\",\n",
        "        \"Explain the research methodology and data sources\"\n",
        "    ],\n",
        "    theme=gr.themes.Soft(),\n",
        "    cache_examples=False,\n",
        "    chatbot=gr.Chatbot(height=500)\n",
        ")\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"üöÄ LAUNCHING ENHANCED GRADIO INTERFACE\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Launch with public shareable link\n",
        "interface.launch(\n",
        "    share=True,  # Creates public link\n",
        "    debug=True,\n",
        "    show_error=True\n",
        ")\n",
        "\n",
        "print(\"\\n‚úÖ Interface launched with general knowledge capabilities!\")\n",
        "print(\"üì± Use the public link above to share with others\")\n",
        "print(\"‚è±Ô∏è Link expires in 72 hours\")\n",
        "print(\"\\nüéØ Agent can now explain price movements using:\")\n",
        "print(\"   - Specific historical data (when available)\")\n",
        "print(\"   - General agricultural economics knowledge\")\n",
        "print(\"   - Weather-price relationships from research\")\n",
        "print(\"   - Fuel price impacts and transportation costs\")\n",
        "print(\"   - Seasonal patterns and market dynamics\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "zdOwkSHFJZts"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
